# ğŸ§  Reconocimiento de Gestos en Tiempo Real

Una aplicaciÃ³n web moderna para el reconocimiento de lenguaje de seÃ±as usando MediaPipe Holistic y redes neuronales.

## âœ¨ CaracterÃ­sticas

- ğŸŒ **Interfaz web moderna** con diseÃ±o responsivo
- ğŸ¥ **Captura de video en tiempo real** desde la cÃ¡mara
- ğŸ§  **Reconocimiento automÃ¡tico** de gestos usando IA
- ğŸ“Š **EstadÃ­sticas en tiempo real** (frames, predicciones, confianza)
- ğŸ¨ **DiseÃ±o atractivo** con gradientes y animaciones
- ğŸ“± **Compatible con mÃ³viles** y diferentes dispositivos

## ğŸš€ InstalaciÃ³n y Uso

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Entrenar el modelo (si no existe)
```bash
cd app
python entrenar_nn_holistic.py
```

### 3. Ejecutar la aplicaciÃ³n
```bash
uvicorn app.main_nn_holistic:app --reload --port 8000
```

### 4. Abrir en el navegador
Ve a `http://localhost:8000` para acceder a la interfaz web.

## ğŸ® CÃ³mo usar la interfaz

1. **Iniciar CÃ¡mara**: Haz clic en "ğŸ¥ Iniciar CÃ¡mara" para comenzar
2. **Esperar Captura**: La aplicaciÃ³n automÃ¡ticamente captura 60 frames
3. **Ver PredicciÃ³n**: El gesto reconocido aparecerÃ¡ en pantalla
4. **Captura Manual**: Usa "ğŸ“¸ Capturar Gesto" para predicciÃ³n manual
5. **Detener**: Usa "â¹ï¸ Detener" para cerrar la cÃ¡mara

## ğŸ“ Estructura del Proyecto

```
HackatonOficial/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main_nn_holistic.py      # API FastAPI principal
â”‚   â”œâ”€â”€ entrenar_nn_holistic.py  # Script de entrenamiento
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html           # PÃ¡gina web principal
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ script.js            # JavaScript para la interfaz
â”‚   â”œâ”€â”€ modelo_nn/               # Modelos entrenados
â”‚   â””â”€â”€ data/                    # Datos de entrenamiento
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ ConfiguraciÃ³n

### ParÃ¡metros del modelo
- **Secuencia**: 60 frames por predicciÃ³n
- **Features**: 147 caracterÃ­sticas por frame (manos + pose)
- **Entrada total**: 8820 valores (60 Ã— 147)

### PersonalizaciÃ³n
Puedes modificar los estilos CSS en `app/templates/index.html` para cambiar la apariencia de la interfaz.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Backend**: FastAPI, PyTorch, MediaPipe
- **Frontend**: HTML5, CSS3, JavaScript (ES6+)
- **IA**: Redes neuronales MLP para clasificaciÃ³n
- **Video**: WebRTC para captura de cÃ¡mara

## ğŸ“ Notas

- La aplicaciÃ³n actualmente simula la extracciÃ³n de landmarks para demostraciÃ³n
- Para uso real, integra MediaPipe.js en el frontend
- El modelo requiere datos de entrenamiento especÃ­ficos
- AsegÃºrate de tener permisos de cÃ¡mara en el navegador

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.